{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NLP_HW3_Majid_Sohrabi.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "bNbhd8n9t14B",
        "5ILnjXSAuruz"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y75pJtX97F6s"
      },
      "source": [
        "# Home Assignment 3 - Natural Language Processing (Majid Sohrabi)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7vXeI989tm31",
        "outputId": "5a5a4cdd-c09e-40f2-e308-7e1b59af3094"
      },
      "source": [
        "pip install opencorpora-tools"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting opencorpora-tools\n",
            "  Downloading https://files.pythonhosted.org/packages/07/50/f268e0f1a1961dab7aa7f0d3f286c7b492c4f3b901211298758ff986772a/opencorpora_tools-0.6-py3-none-any.whl\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.7/dist-packages (from opencorpora-tools) (4.2.6)\n",
            "Installing collected packages: opencorpora-tools\n",
            "Successfully installed opencorpora-tools-0.6\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aeJin3SCtT6U"
      },
      "source": [
        "import nltk\n",
        "import random\n",
        "import opencorpora\n",
        "from sklearn.metrics import accuracy_score, recall_score, precision_score\n",
        "import matplotlib.pyplot as plt\n",
        "plt.style.use('ggplot')\n",
        "\n",
        "# Task 3\n",
        "from nltk import load_parser\n",
        "\n",
        "# Task 4\n",
        "from nltk.sem.drt import DrtParser"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bNbhd8n9t14B"
      },
      "source": [
        "## Task 1\n",
        "  1. Translate into predicate logic:\n",
        "* a. Angus likes Cyril and Irene hates Cyril.\n",
        "* b. Bruce loves himself and Pat does too.\n",
        "* c. Cyril saw Bertie, but Angus didn't.\n",
        "* d. Cyril is a fourlegged friend.\n",
        "* e. Angus likes someone and someone likes Julia.\n",
        "* f. Angus loves a dog who loves him.\n",
        "* g. Nobody coughed or sneezed.\n",
        "* h. Cyril likes everyone except for Irene."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pi_JyyYCtlpe",
        "outputId": "1f43f482-edbd-4cae-98b4-fdcdb463c8d9"
      },
      "source": [
        "# a. Predicate logic for \"Angus likes Cyril and Irene hates Cyril.\" expression\n",
        "nltk.Expression.fromstring(\"like(Angus, Cyril) & hate(Irene, Cyril)\")\n",
        "\n",
        "# b. Predicate logic for \"Bruce loves himself and Pat does too.\" expression\n",
        "nltk.Expression.fromstring(\"love(Bruce, Bruce) & hate(Pat, Pat)\")\n",
        "\n",
        "# c. Predicate logic for \"Cyril saw Bertie, but Angus didn't.\" expression\n",
        "nltk.Expression.fromstring(\"saw(Cyril, Bertie) & !saw(Angus, Bertie)\")\n",
        "\n",
        "# d. Predicate logic for \"Cyril is a fourlegged friend.\" expression\n",
        "nltk.Expression.fromstring(\"has_four_legs(Cyril) & friendly(Cyril)\")\n",
        "\n",
        "# e. Predicate logic for \"Angus likes someone and someone likes Julia.\" expression\n",
        "nltk.Expression.fromstring(\"(exists x. like(Angus, x)) & (exists y. like(y, Julia))\")\n",
        "\n",
        "# f. Predicate logic for Angus loves a dog who loves him.\"\" expression\n",
        "nltk.Expression.fromstring(\"exists x. (love(Angus, x) & love(x, Angus))\")\n",
        "\n",
        "# g. Predicate logic for \"Nobody coughed or sneezed.\" expression\n",
        "nltk.Expression.fromstring(\"all x. - (cough(x) | sneeze(x))\")\n",
        "\n",
        "# h. Predicate logic for \"Cyril likes everyone except for Irene.\" expression\n",
        "nltk.Expression.fromstring(\"all x. (x != Irene -> like(Cyril, x))\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<AllExpression all x.(-(x = Irene) -> like(Cyril,x))>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5ILnjXSAuruz"
      },
      "source": [
        "## Task 2\n",
        "  2. Translate into lambda expressions over a predicate logic formulas:\n",
        "* a. feed Cyril and give a capuccino to Angus\n",
        "* b. be given a book by Pat\n",
        "* c. be loved or detested by everyone\n",
        "* d. be loved by everyone and detested by no-one"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f7EAIOOZutbh"
      },
      "source": [
        "expression_reader = nltk.sem.Expression.fromstring\n",
        "\n",
        "# a. Translate into lambda expressions over a predicate logic formulas: \"feed Cyril and give a capuccino to Angus\" expression\n",
        "first_expre = expression_reader(r'\\x.(feed(x, cyril) & exists y.(cappuccino(y) & give(x, y, angus)))').simplify()\n",
        "\n",
        "# b. Translate into lambda expressions over a predicate logic formulas: \"be given a book by Pat\" expression\n",
        "second_expre = expression_reader(r'\\x.exists y.(book(y) & give(pat, y, x))').simplify()\n",
        "\n",
        "# c. Translate into lambda expressions over a predicate logic formulas: \"be loved or detested by everyone\" expression\n",
        "third_expre = expression_reader(r'\\x. all y.(love(y, x) | detest(y, x))').simplify()\n",
        "\n",
        "# d. Translate into lambda expressions over a predicate logic formulas: \"be loved by everyone and detested by no-one\" expression\n",
        "fourth_expre = expression_reader(r'\\x. all y.(love(y, x) & -detest(y, x))').simplify()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OPHw74vJM8EB",
        "outputId": "9a78e2a4-f2af-49bd-87da-a1d2444560a8"
      },
      "source": [
        "first_expre"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<LambdaExpression \\x.(feed(x,cyril) & exists y.(cappuccino(y) & give(x,y,angus)))>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cHB4A-ilNC1a",
        "outputId": "1a6d40da-a587-482b-9fd6-edb3b9768a31"
      },
      "source": [
        "second_expre"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<LambdaExpression \\x.exists y.(book(y) & give(pat,y,x))>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gUxS2ACqNCy6",
        "outputId": "afd78077-1e3c-4b74-a754-1183f070ed9c"
      },
      "source": [
        "third_expre"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<LambdaExpression \\x.all y.(love(y,x) | detest(y,x))>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R4OUs--INCt4",
        "outputId": "3effb60d-7d52-47d4-8684-874d1b641647"
      },
      "source": [
        "fourth_expre"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<LambdaExpression \\x.all y.(love(y,x) & -detest(y,x))>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xI9UZNLxuvrM"
      },
      "source": [
        "## Task 3\n",
        "  3. For the following discourse create a grammar which translates the sentences into predicate logic. Manually create a model to check the truth of the resulting formulas. \n",
        "* a. A black kitten saw a mouse. The kitten rushed after it.\n",
        "The mouse jumped into a jar [of flour].\n",
        "The kitten followed it.\n",
        "The mouse ran away.\n",
        "A white kitten got out of the jar.\n",
        "\n",
        "  You can omit the part in the square brackets if there is a problem with it. Treat the article 'the' as the quantifier 'exists unique'. The lambda expression for it would be \\P Q.exists x.((P(x) & Q(x)) & all y.(P(y) -> (x = y))). If there is a problem with the pronoun 'it', you can replace it with the noun phrase 'the mouse' directly in the text and process the modified discourse.\n",
        "\n",
        "  Take the following grammar as an example:\n",
        "nltk.data.show_cfg('grammars/book_grammars/discourse.fcfg')"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7gww8hMOu8ss",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4471afe6-e82c-49db-f6a7-01f0898f7531"
      },
      "source": [
        "nltk.download('book_grammars')\n",
        "nltk.data.show_cfg(\"Task3_grammar.fcfg\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package book_grammars to /root/nltk_data...\n",
            "[nltk_data]   Package book_grammars is already up-to-date!\n",
            "% start S\n",
            "# Grammar Rules\n",
            "S[SEM = <app(?subj,?vp)>] -> NP[NUM=?n,SEM=?subj] VP[NUM=?n,SEM=?vp]\n",
            "NP[NUM=?n,SEM=<app(?det,?nom)> ] -> Det[NUM=?n,SEM=?det]  Nom[NUM=?n,SEM=?nom]\n",
            "NP[LOC=?l,NUM=?n,SEM=?np] -> PropN[LOC=?l,NUM=?n,SEM=?np]\n",
            "NP[-LOC,NUM=sg,SEM=<\\Q. (- exists x. (person(x) & Q(x)))>] -> 'nobody' | 'Nobody'\n",
            "NP[-LOC,NUM=sg,SEM=<\\Q. exists x. (person(x) & Q(x))>] -> 'somebody' | 'Somebody'\n",
            "Pred[SEM=?prd] -> PredN[SEM=?prd] | PP[+LOC,+PRED,SEM=?prd] | Adj[SEM=?prd]\n",
            "PredN[NUM=?n, SEM=?nom] -> Det[NUM=?n] Nom[NUM=?n, SEM=?nom]\n",
            "Nom[NUM=?n,SEM=?nom] -> N[NUM=?n,SEM=?nom]\n",
            "Nom[NUM=?n,SEM=<app(?pp,?nom)>] -> N[NUM=?n,SEM=?nom] PP[SEM=?pp]\n",
            "Nom[NUM=?n,SEM=<?adj(?nom)>] -> Adj[SEM=?adj] N[NUM=?n,SEM=?nom]\n",
            "VP[NUM=?n,SEM=<app(?v,?obj)>] -> TV[NUM=?n,SEM=?v] NP[SEM=?obj]\n",
            "VP[NUM=?n,SEM=<app(?v,?p)>] -> IV[NUM=?n,SEM=?v] P[LOC=?l,SEM=?p]\n",
            "VP[NUM=?n,SEM=?v] -> IV[NUM=?n,SEM=?v]\n",
            "VP[NUM=?n,SEM=<app(?pp,?vp)>] -> VP[NUM=?n,SEM=?vp] PP[-PRED,SEM=?pp]\n",
            "PP[LOC=?l,PRED=?prd,SEM=<app(?p,?np)>] -> P[LOC=?l,PRED=?prd,SEM=?p] NP[LOC=?l,SEM=?np]\n",
            "# Lexical Rules\n",
            "PropN[-LOC,NUM=sg,SEM=<\\P.P(John)>] -> 'John'\n",
            "PropN[-LOC,NUM=sg,SEM=<\\P.P(Mary)>] -> 'Mary'\n",
            "PropN[-LOC,NUM=sg,SEM=<\\P.P(Suzie)>] -> 'Suzie'\n",
            "PropN[-LOC,NUM=sg,SEM=<\\P.P(Vincent)>] -> 'Vincent'\n",
            "PropN[-LOC,NUM=sg,SEM=<\\P.P(Mia)>] -> 'Mia'\n",
            "PropN[-LOC,NUM=sg,SEM=<\\P.P(Marsellus)>] -> 'Marsellus'\n",
            "PropN[-LOC,NUM=sg,SEM=<\\P.P(Fido)>] -> 'Fido'\n",
            "PropN[+LOC, NUM=sg,SEM=<\\P.P(Noosa)>] -> 'Noosa'\n",
            "NP[-LOC, NUM=sg, SEM=<\\P.\\x.P(x)>] -> 'who' | 'Who'\n",
            "Det[NUM=sg,SEM=<\\P Q.all x.(P(x) -> Q(x))>] -> 'every' | 'Every' \n",
            "Det[NUM=pl,SEM=<\\P Q.all x.(P(x) -> Q(x))>] -> 'all' | 'All'\n",
            "Det[SEM=<\\P Q.exists x.(P(x) & Q(x))>] -> 'some' | 'Some'\n",
            "Det[NUM=sg,SEM=<\\P Q.exists x.(P(x) & Q(x))>] -> 'a' | 'A'\n",
            "Det[NUM=sg,SEM=<\\P Q.(- exists x.(P(x) & Q(x)))>] -> 'no' | 'No'\n",
            "Det[NUM=sg,SEM=<\\P Q.exists x.((P(x) & Q(x)) & all y.(P(y) -> (x = y)))>] -> 'the' | 'The' \n",
            "N[NUM=sg,SEM=<\\x.boy(x)>] -> 'boy'\n",
            "N[NUM=pl,SEM=<\\x.boy(x)>] -> 'boys' \n",
            "N[NUM=sg,SEM=<\\x.girl(x)>] -> 'girl'\n",
            "N[NUM=pl,SEM=<\\x.girl(x)>] -> 'girls'\n",
            "N[NUM=sg,SEM=<\\x.dog(x)>] -> 'dog'\n",
            "N[NUM=pl,SEM=<\\x.dog(x)>] -> 'dogs'\n",
            "N[NUM=sg,SEM=<\\x.student(x)>] -> 'student'\n",
            "N[NUM=pl,SEM=<\\x.student(x)>] -> 'students'\n",
            "N[NUM=sg,SEM=<\\x.person(x)>] -> 'person'\n",
            "N[NUM=pl,SEM=<\\x.person(x)>] -> 'persons'\n",
            "N[NUM=sg,SEM=<\\x.boxerdog(x)>] -> 'boxer'\n",
            "N[NUM=pl,SEM=<\\x.boxerdog(x)>] -> 'boxers'\n",
            "N[NUM=sg,SEM=<\\x.boxer(x)>] -> 'boxer'\n",
            "N[NUM=pl,SEM=<\\x.boxer(x)>] -> 'boxers'\n",
            "N[NUM=sg,SEM=<\\x.garden(x)>] -> 'garden'\n",
            "N[NUM=sg,SEM=<\\x.kitchen(x)>] -> 'kitchen'\n",
            "N[NUM=sg,SEM=<\\x.kitten(x)>] -> 'kitten'\n",
            "N[NUM=sg,SEM=<\\x.mouse(x)>] -> 'mouse'\n",
            "N[NUM=sg,SEM=<\\x.jar(x)>] -> 'jar'\n",
            "N[NUM=sg,SEM=<\\x.flour(x)>] -> 'flour'\n",
            "Adj[SEM=<\\x.happy(x)>] -> 'happy'\n",
            "Adj[SEM=<\\x.drunk(x)>] -> 'drunk'\n",
            "Adj[SEM=<\\x.married(x)>] -> 'married'\n",
            "Adj[SEM=<\\P x.(white(x) & P(x))>] -> 'white'\n",
            "Adj[SEM=<\\P x.(black(x) & P(x))>] -> 'black'\n",
            "TV[NUM=sg,SEM=<\\X y.X(\\x.chase(y,x))>,tns=pres] -> 'chases'\n",
            "TV[NUM=pl,SEM=<\\X y.X(\\x.chase(y,x))>,tns=pres] -> 'chase'\n",
            "TV[NUM=sg,SEM=<\\X y.X(\\x.marry(y,x))>,tns=pres] -> 'marries'\n",
            "TV[NUM=pl,SEM=<\\X y.X(\\x.marry(y,x))>,tns=pres] -> 'marry'\n",
            "TV[NUM=sg,SEM=<\\X y.X(\\x.know(y,x))>,tns=pres] -> 'knows'\n",
            "TV[NUM=pl,SEM=<\\X y.X(\\x.know(y,x))>,tns=pres] -> 'know'\n",
            "TV[NUM=sg,SEM=<\\X y.X(\\x.see(y,x))>,tns=pres] -> 'sees'\n",
            "TV[NUM=pl,SEM=<\\X y.X(\\x.see(y,x))>,tns=pres] -> 'see'\n",
            "TV[SEM=<\\X y.X(\\x.see(y,x))>,tns=past] -> 'saw'\n",
            "TV[SEM=<\\X y.X(\\x.follow(y,x))>,tns=past] -> 'followed'\n",
            "TV[SEM=<\\X y.X(\\x.rush_after(y,x))>,tns=past] -> 'rushed' 'after'\n",
            "IV[NUM=sg,SEM=<\\x.bark(x)>,tns=pres] -> 'barks'\n",
            "IV[NUM=pl,SEM=<\\x.bark(x)>,tns=pres] -> 'bark'\n",
            "IV[NUM=sg,SEM=<\\x.walk(x)>,tns=pres] -> 'walks'\n",
            "IV[NUM=pl,SEM=<\\x.walk(x)>,tns=pres] -> 'walk'\n",
            "IV[NUM=pl,SEM=<\\x.dance(x)>,tns=pres] -> 'dance'\n",
            "IV[NUM=sg,SEM=<\\x.dance(x)>,tns=pres] -> 'dances'\n",
            "TV[SEM=<\\X y.X(\\x.jump_into(y,x))>,tns=past] -> 'jumped' 'into'\n",
            "IV[NUM=sg,SEM=<\\x.run_away(x)>,tns=past] -> 'ran' 'away'\n",
            "TV[SEM=<\\X y.X(\\x.get_out_of(y,x))>,tns=past] -> 'got' 'out' 'of'\n",
            "Aux[+COP,NUM=sg,SEM=<\\P x.P(x)>,tns=pres] -> 'is'\n",
            "Aux[+COP,NUM=pl,SEM=<\\P x.P(x)>,tns=pres] -> 'are'\n",
            "Aux[-COP,NUM=sg,SEM=<\\P x.P(x)>,tns=pres] -> 'does'\n",
            "Aux[-COP,NUM=pl,SEM=<\\P x.P(x)>,tns=pres] -> 'do'\n",
            "P[+LOC,-PRED,SEM=<\\X P x.X(\\y.(P(x) & in(x,y)))>] -> 'in'\n",
            "P[+LOC,+PRED,SEM=<\\X x.X(\\y.in(x,y))>] -> 'in'\n",
            "P[-LOC,SEM=<\\X P x.X(\\y.(P(x) & with(x,y)))>] -> 'with'\n",
            "P[+LOC,-PRED,SEM=<\\X P x.X(\\y.(P(x) & of(x,y)))>] ->  'of'\n",
            "Neg[SEM=<\\T P.T(\\x.(- P(x)))>] -> 'not'\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XMzZhhKXZ8AL"
      },
      "source": [
        "mmy_grammar = \"\"\"\n",
        "\n",
        "% start S\n",
        "\n",
        "# GRAMMAR RULES\n",
        "\n",
        "S[SEM = <app(?subj,?vp)>] -> NP[NUM=?n,SEM=?subj] VP[NUM=?n,SEM=?vp]\n",
        "NP[NUM=?n,SEM=<app(?det,?nom)> ] -> Det[NUM=?n,SEM=?det]  Nom[NUM=?n,SEM=?nom]\n",
        "Nom[NUM=?n,SEM=?nom] -> N[NUM=?n,SEM=?nom]\n",
        "Nom[NUM=?n,SEM=<?adj(?nom)>] -> Adj[SEM=?adj] N[NUM=?n,SEM=?nom] \n",
        "VP[NUM=?n,SEM=<app(?v,?obj)>] -> TV[NUM=?n,SEM=?v] NP[SEM=?obj]\n",
        "VP[NUM=?n,SEM=?v] -> IV[NUM=?n,SEM=?v]\n",
        "\n",
        "\n",
        "# LEXICAL RULES\n",
        "\n",
        "# Articles\n",
        "Det[NUM=sg,SEM=<\\\\P Q.exists x.(P(x) & Q(x))>] -> 'a' | 'A'\n",
        "Det[NUM=sg,SEM=<\\\\P Q.exists x.((P(x) & Q(x)) & all y.(P(y) -> (x = y)))>] -> 'the' | 'The' \n",
        "\n",
        "# Nouns\n",
        "N[NUM=sg,SEM=<\\\\x.kitten(x)>] -> 'kitten'\n",
        "N[NUM=sg,SEM=<\\\\x.mouse(x)>] -> 'mouse' \n",
        "N[NUM=sg,SEM=<\\\\x.jar(x)>] -> 'jar'\n",
        "\n",
        "# Adjectives\n",
        "Adj[SEM=<\\\\P x.(white(x) & P(x))>] -> 'white'\n",
        "Adj[SEM=<\\\\P x.(black(x) & P(x))>] -> 'black'\n",
        "\n",
        "# Verbs\n",
        "TV[SEM=<\\\\X y.X(\\\\x.see(y,x))>,tns=past] -> 'saw'\n",
        "TV[SEM=<\\\\X y.X(\\\\x.rush_after(y,x))>,tns=past] -> 'rushed' 'after'\n",
        "TV[SEM=<\\\\X y.X(\\\\x.jump_into(y,x))>,tns=past] -> 'jumped' 'into'\n",
        "TV[SEM=<\\\\X y.X(\\\\x.follow(y,x))>,tns=past] -> 'followed'\n",
        "IV[SEM=<\\\\x.run_away(x)>,tns=past] -> 'ran' 'away'\n",
        "TV[SEM=<\\\\X y.X(\\\\x.get_out_of(y,x))>,tns=past] -> 'got' 'out' 'of'\n",
        "\"\"\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zzn8hGS-aACp"
      },
      "source": [
        "f = open('mmy_grammar.fcfg', 'a')\n",
        "for line in mmy_grammar:\n",
        "  f.write(line)\n",
        "f.close()\n",
        "\n",
        "parser = load_parser('mmy_grammar.fcfg', trace = 0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JwlA_Xcy2eC6"
      },
      "source": [
        "Lets define sentenses"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JgB4oVQk2hTb"
      },
      "source": [
        "target_sentences = ['A black kitten saw a mouse',\n",
        "                    'The kitten rushed after the mouse',\n",
        "                    'The mouse jumped into a jar',\n",
        "                    'The kitten followed the mouse',\n",
        "                    'The mouse ran away',\n",
        "                    'A white kitten got out of the jar']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mpbFIGk3KOdv",
        "outputId": "fea542f6-68b8-4fca-e3fc-644968b65a9a"
      },
      "source": [
        "dom = {'k', 'm', 'j'}\n",
        "target_ch = \"\"\"\n",
        "\n",
        "kitten => {k}\n",
        "mouse => {m}\n",
        "jar => {j}\n",
        "\n",
        "black => {k}\n",
        "white => {k}\n",
        "\n",
        "see => {(k, m)}\n",
        "rush_after => {(k, m)}\n",
        "jump_into => {(m, j)}\n",
        "follow => {(k, m)}\n",
        "run_away => {m}\n",
        "get_out_of => {(k, j)}\n",
        "\"\"\"\n",
        "\n",
        "Valuat = nltk.Valuation.fromstring(target_ch)\n",
        "assign = nltk.Assignment(dom)\n",
        "mod = nltk.Model(dom, Valuat)\n",
        "\n",
        "'''\n",
        "tsentence_ch = zip(target_sentences, target_ch)\n",
        "for tsent, ch in tsentence_ch :\n",
        "  print(\"The Target Sentence Is: ```\", tsent, \"```\")\n",
        "  Valuat = nltk.Valuation.fromstring(ch)\n",
        "  print(nltk.evaluate_sents([tsent], 'Task3_grammar.fcfg', mod, assign))\n",
        "  print('\\n\\n')\n",
        "\n",
        "print('*' * 100, '\\n')\n",
        "'''\n",
        "\n",
        "for tsent in target_sentences :\n",
        "  print(\"The Target Sentence Is: ```\", tsent, \"```\")\n",
        "  tokens = tsent.split()\n",
        "  \n",
        "  for mytree in parser.parse(tokens):\n",
        "    print(nltk.evaluate_sents([tsent], 'Task3_grammar.fcfg', mod, assign))\n",
        "    print('\\n\\n')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The Target Sentence Is: ``` A black kitten saw a mouse ```\n",
            "[[(Tree(S[SEM=<exists x.(black(x) & kitten(x) & exists z411.(mouse(z411) & see(x,z411)))>], [Tree(NP[NUM='sg', SEM=<\\Q.exists x.(black(x) & kitten(x) & Q(x))>], [Tree(Det[NUM='sg', SEM=<\\P Q.exists x.(P(x) & Q(x))>], ['A']), Tree(Nom[NUM='sg', SEM=<\\x.(black(x) & kitten(x))>], [Tree(Adj[SEM=<\\P x.(black(x) & P(x))>], ['black']), Tree(N[NUM='sg', SEM=<\\x.kitten(x)>], ['kitten'])])]), Tree(VP[NUM=?n, SEM=<\\y.exists x.(mouse(x) & see(y,x))>], [Tree(TV[SEM=<\\X y.X(\\x.see(y,x))>, tns='past'], ['saw']), Tree(NP[NUM='sg', SEM=<\\Q.exists x.(mouse(x) & Q(x))>], [Tree(Det[NUM='sg', SEM=<\\P Q.exists x.(P(x) & Q(x))>], ['a']), Tree(Nom[NUM='sg', SEM=<\\x.mouse(x)>], [Tree(N[NUM='sg', SEM=<\\x.mouse(x)>], ['mouse'])])])])]), <ExistsExpression exists x.(black(x) & kitten(x) & exists z411.(mouse(z411) & see(x,z411)))>, True)]]\n",
            "\n",
            "\n",
            "\n",
            "The Target Sentence Is: ``` The kitten rushed after the mouse ```\n",
            "[[(Tree(S[SEM=<exists x.(kitten(x) & exists z415.(mouse(z415) & rush_after(x,z415) & all z414.(mouse(z414) -> (z415 = z414))) & all y.(kitten(y) -> (x = y)))>], [Tree(NP[NUM='sg', SEM=<\\Q.exists x.(kitten(x) & Q(x) & all y.(kitten(y) -> (x = y)))>], [Tree(Det[NUM='sg', SEM=<\\P Q.exists x.(P(x) & Q(x) & all y.(P(y) -> (x = y)))>], ['The']), Tree(Nom[NUM='sg', SEM=<\\x.kitten(x)>], [Tree(N[NUM='sg', SEM=<\\x.kitten(x)>], ['kitten'])])]), Tree(VP[NUM=?n, SEM=<\\y.exists x.(mouse(x) & rush_after(y,x) & all z414.(mouse(z414) -> (x = z414)))>], [Tree(TV[SEM=<\\X y.X(\\x.rush_after(y,x))>, tns='past'], ['rushed', 'after']), Tree(NP[NUM='sg', SEM=<\\Q.exists x.(mouse(x) & Q(x) & all y.(mouse(y) -> (x = y)))>], [Tree(Det[NUM='sg', SEM=<\\P Q.exists x.(P(x) & Q(x) & all y.(P(y) -> (x = y)))>], ['the']), Tree(Nom[NUM='sg', SEM=<\\x.mouse(x)>], [Tree(N[NUM='sg', SEM=<\\x.mouse(x)>], ['mouse'])])])])]), <ExistsExpression exists x.(kitten(x) & exists z415.(mouse(z415) & rush_after(x,z415) & all z414.(mouse(z414) -> (z415 = z414))) & all y.(kitten(y) -> (x = y)))>, True)]]\n",
            "\n",
            "\n",
            "\n",
            "The Target Sentence Is: ``` The mouse jumped into a jar ```\n",
            "[[(Tree(S[SEM=<exists x.(mouse(x) & exists z417.(jar(z417) & jump_into(x,z417)) & all y.(mouse(y) -> (x = y)))>], [Tree(NP[NUM='sg', SEM=<\\Q.exists x.(mouse(x) & Q(x) & all y.(mouse(y) -> (x = y)))>], [Tree(Det[NUM='sg', SEM=<\\P Q.exists x.(P(x) & Q(x) & all y.(P(y) -> (x = y)))>], ['The']), Tree(Nom[NUM='sg', SEM=<\\x.mouse(x)>], [Tree(N[NUM='sg', SEM=<\\x.mouse(x)>], ['mouse'])])]), Tree(VP[NUM=?n, SEM=<\\y.exists x.(jar(x) & jump_into(y,x))>], [Tree(TV[SEM=<\\X y.X(\\x.jump_into(y,x))>, tns='past'], ['jumped', 'into']), Tree(NP[NUM='sg', SEM=<\\Q.exists x.(jar(x) & Q(x))>], [Tree(Det[NUM='sg', SEM=<\\P Q.exists x.(P(x) & Q(x))>], ['a']), Tree(Nom[NUM='sg', SEM=<\\x.jar(x)>], [Tree(N[NUM='sg', SEM=<\\x.jar(x)>], ['jar'])])])])]), <ExistsExpression exists x.(mouse(x) & exists z417.(jar(z417) & jump_into(x,z417)) & all y.(mouse(y) -> (x = y)))>, True)]]\n",
            "\n",
            "\n",
            "\n",
            "The Target Sentence Is: ``` The kitten followed the mouse ```\n",
            "[[(Tree(S[SEM=<exists x.(kitten(x) & exists z421.(mouse(z421) & follow(x,z421) & all z420.(mouse(z420) -> (z421 = z420))) & all y.(kitten(y) -> (x = y)))>], [Tree(NP[NUM='sg', SEM=<\\Q.exists x.(kitten(x) & Q(x) & all y.(kitten(y) -> (x = y)))>], [Tree(Det[NUM='sg', SEM=<\\P Q.exists x.(P(x) & Q(x) & all y.(P(y) -> (x = y)))>], ['The']), Tree(Nom[NUM='sg', SEM=<\\x.kitten(x)>], [Tree(N[NUM='sg', SEM=<\\x.kitten(x)>], ['kitten'])])]), Tree(VP[NUM=?n, SEM=<\\y.exists x.(mouse(x) & follow(y,x) & all z420.(mouse(z420) -> (x = z420)))>], [Tree(TV[SEM=<\\X y.X(\\x.follow(y,x))>, tns='past'], ['followed']), Tree(NP[NUM='sg', SEM=<\\Q.exists x.(mouse(x) & Q(x) & all y.(mouse(y) -> (x = y)))>], [Tree(Det[NUM='sg', SEM=<\\P Q.exists x.(P(x) & Q(x) & all y.(P(y) -> (x = y)))>], ['the']), Tree(Nom[NUM='sg', SEM=<\\x.mouse(x)>], [Tree(N[NUM='sg', SEM=<\\x.mouse(x)>], ['mouse'])])])])]), <ExistsExpression exists x.(kitten(x) & exists z421.(mouse(z421) & follow(x,z421) & all z420.(mouse(z420) -> (z421 = z420))) & all y.(kitten(y) -> (x = y)))>, True)]]\n",
            "\n",
            "\n",
            "\n",
            "The Target Sentence Is: ``` The mouse ran away ```\n",
            "[[(Tree(S[SEM=<exists x.(mouse(x) & run_away(x) & all y.(mouse(y) -> (x = y)))>], [Tree(NP[NUM='sg', SEM=<\\Q.exists x.(mouse(x) & Q(x) & all y.(mouse(y) -> (x = y)))>], [Tree(Det[NUM='sg', SEM=<\\P Q.exists x.(P(x) & Q(x) & all y.(P(y) -> (x = y)))>], ['The']), Tree(Nom[NUM='sg', SEM=<\\x.mouse(x)>], [Tree(N[NUM='sg', SEM=<\\x.mouse(x)>], ['mouse'])])]), Tree(VP[NUM='sg', SEM=<\\x.run_away(x)>], [Tree(IV[NUM='sg', SEM=<\\x.run_away(x)>, tns='past'], ['ran', 'away'])])]), <ExistsExpression exists x.(mouse(x) & run_away(x) & all y.(mouse(y) -> (x = y)))>, True)]]\n",
            "\n",
            "\n",
            "\n",
            "The Target Sentence Is: ``` A white kitten got out of the jar ```\n",
            "[[(Tree(S[SEM=<exists x.(white(x) & kitten(x) & exists z426.(jar(z426) & get_out_of(x,z426) & all z424.(jar(z424) -> (z426 = z424))))>], [Tree(NP[NUM='sg', SEM=<\\Q.exists x.(white(x) & kitten(x) & Q(x))>], [Tree(Det[NUM='sg', SEM=<\\P Q.exists x.(P(x) & Q(x))>], ['A']), Tree(Nom[NUM='sg', SEM=<\\x.(white(x) & kitten(x))>], [Tree(Adj[SEM=<\\P x.(white(x) & P(x))>], ['white']), Tree(N[NUM='sg', SEM=<\\x.kitten(x)>], ['kitten'])])]), Tree(VP[NUM=?n, SEM=<\\y.exists x.(jar(x) & get_out_of(y,x) & all z424.(jar(z424) -> (x = z424)))>], [Tree(TV[SEM=<\\X y.X(\\x.get_out_of(y,x))>, tns='past'], ['got', 'out', 'of']), Tree(NP[NUM='sg', SEM=<\\Q.exists x.(jar(x) & Q(x) & all y.(jar(y) -> (x = y)))>], [Tree(Det[NUM='sg', SEM=<\\P Q.exists x.(P(x) & Q(x) & all y.(P(y) -> (x = y)))>], ['the']), Tree(Nom[NUM='sg', SEM=<\\x.jar(x)>], [Tree(N[NUM='sg', SEM=<\\x.jar(x)>], ['jar'])])])])]), <ExistsExpression exists x.(white(x) & kitten(x) & exists z426.(jar(z426) & get_out_of(x,z426) & all z424.(jar(z424) -> (z426 = z424))))>, True)]]\n",
            "\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wf85qrhSu90N"
      },
      "source": [
        "## Task 4\n",
        "  4. The same as in the previous task but instead of predicate logic formulas translate the sentences into DRSs. Treat the article 'the' the same way as 'a', but in addition mark the variable with PRO predicate to show that it requires resolution in the same way as pronouns. Combine all DRSs into one using '+' operation and manually add resolution for all PRO variables. I. e. add conditions of the form (x = y), where x is the variable marked with PRO and y is its antecedent (the object which the pronoun or the noun phrase refers to). You can add them by creating a separate DRS and combining it with the rest of DRSs using '+' operation. After that use simplify() to get one DRS as a result of 'addition', then eliminate_equality() to reduce the number of variables, the fol() to convert the resulting DRS into predicate logic and check the truth of the formula in your model.\n",
        "\n",
        "  Take the following grammar as an example:\n",
        "nltk.data.show_cfg('grammars/book_grammars/drt.fcfg')"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xz3puBfLUc0d"
      },
      "source": [
        "def parse_p(parser, sentence):\n",
        "    tokens = sentence.split()\n",
        "    for tree in parser.parse(tokens):\n",
        "        return(tree.label()['SEM'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5LYCIDD2TwaQ",
        "outputId": "cdae47c8-1e42-45ee-cc47-8bd911286998"
      },
      "source": [
        "nltk.data.show_cfg('Task4_DRS.fcfg')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "% start S\n",
            "# Grammar Rules\n",
            "S[SEM = <app(?subj,?vp)>] -> NP[NUM=?n,SEM=?subj] VP[NUM=?n,SEM=?vp]\n",
            "NP[NUM=?n,SEM=<app(?det,?nom)> ] -> Det[NUM=?n,SEM=?det]  Nom[NUM=?n,SEM=?nom]\n",
            "NP[LOC=?l,NUM=?n,SEM=?np] -> PropN[LOC=?l,NUM=?n,SEM=?np]\n",
            "Nom[NUM=?n,SEM=?nom] -> N[NUM=?n,SEM=?nom]\n",
            "Nom[NUM=?n,SEM=<app(?pp,?nom)>] -> N[NUM=?n,SEM=?nom] PP[SEM=?pp]\n",
            "Nom[NUM=?n,SEM=<app(?adj,?nom)>] -> Adj[SEM=?adj] N[NUM=?n,SEM=?nom]\n",
            "VP[NUM=?n,SEM=?v] -> IV[NUM=?n,SEM=?v]\n",
            "VP[NUM=?n,SEM=<app(?v,?obj)>] -> TV[NUM=?n,SEM=?v] NP[SEM=?obj]\n",
            "# Lexical Rules\n",
            "Det[NUM=sg,SEM=<\\P Q.((DRS([x],[])+P(x))+Q(x))>] -> 'a' | 'A'\n",
            "Det[NUM=sg,SEM=<\\P Q.((DRS([x],[])+P(x))+Q(x))>] -> 'the' | 'The'\n",
            "Adj[SEM=<\\P x.(DRS([],[black(x)]) + P(x))>] -> 'black'\n",
            "Adj[SEM=<\\P x.(DRS([],[white(x)]) + P(x))>] -> 'white'\n",
            "N[NUM=sg,SEM=<\\x.DRS([],[kitten(x)])>] -> 'kitten'\n",
            "N[NUM=sg,SEM=<\\x.DRS([],[mouse(x)])>] -> 'mouse' \n",
            "N[NUM=sg,SEM=<\\x.DRS([],[jar(x)])>] -> 'jar'\n",
            "IV[NUM=sg,SEM=<\\x.DRS([],[run_away(x)])>,tns=past] -> 'ran' 'away'\n",
            "TV[SEM=<\\X x.X(\\y.DRS([],[rush_after(x,y)]))>,tns=past] -> 'rushed' 'after'\n",
            "TV[SEM=<\\X x.X(\\y.DRS([],[jump_into(x,y)]))>,tns=past] -> 'jumped' 'into'\n",
            "TV[SEM=<\\X x.X(\\y.DRS([],[get_out_of(x,y)]))>,tns=past] -> 'got' 'out' 'of'\n",
            "TV[SEM=<\\X x.X(\\y.DRS([],[see(x,y)]))>,tns=past] -> 'saw'\n",
            "TV[SEM=<\\X x.X(\\y.DRS([],[follow(x,y)]))>,tns=past] -> 'followed'\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a_Yx_xJDTkeb"
      },
      "source": [
        "grammar_str = \"\"\"\n",
        "\n",
        "% start S\n",
        "\n",
        "# GRAMMAR RULES\n",
        "\n",
        "S[SEM = <app(?subj,?vp)>] -> NP[NUM=?n,SEM=?subj] VP[NUM=?n,SEM=?vp]\n",
        "NP[NUM=?n,SEM=<app(?det,?nom)> ] -> Det[NUM=?n,SEM=?det]  Nom[NUM=?n,SEM=?nom]\n",
        "Nom[NUM=?n,SEM=?nom] -> N[NUM=?n,SEM=?nom]\n",
        "Nom[NUM=?n,SEM=<?adj(?nom)>] -> Adj[SEM=?adj] N[NUM=?n,SEM=?nom] \n",
        "VP[NUM=?n,SEM=<app(?v,?obj)>] -> TV[NUM=?n,SEM=?v] NP[SEM=?obj]\n",
        "VP[NUM=?n,SEM=?v] -> IV[NUM=?n,SEM=?v]\n",
        "\n",
        "\n",
        "# LEXICAL RULES\n",
        "\n",
        "# Articles\n",
        "Det[NUM=sg,SEM=<\\\\P Q.(DRS([x],[]) + P(x) + Q(x))>] -> 'a' | 'A'\n",
        "Det[NUM=sg,SEM=<\\\\P Q.((DRS([x],[PRO(x)]) + P(x)) + Q(x))>] -> 'the' | 'The'\n",
        "\n",
        "# Nouns\n",
        "N[NUM=sg,SEM=<\\\\x.DRS([],[kitten(x)])>] -> 'kitten'\n",
        "N[NUM=sg,SEM=<\\\\x.DRS([],[mouse(x)])>] -> 'mouse' \n",
        "N[NUM=sg,SEM=<\\\\x.DRS([],[jar(x)])>] -> 'jar'\n",
        "\n",
        "# Adjectives\n",
        "Adj[SEM=<\\\\P x.(DRS([],[white(x)]) + P(x))>] -> 'white'\n",
        "Adj[SEM=<\\\\P x.(DRS([],[black(x)]) + P(x))>] -> 'black'\n",
        "\n",
        "# Verbs\n",
        "TV[SEM=<\\\\X x.X(\\\\y.DRS([],[see(x,y)]))>,tns=past] -> 'saw'\n",
        "TV[SEM=<\\\\X x.X(\\\\y.DRS([],[rush_after(x,y)]))>,tns=past] -> 'rushed' 'after'\n",
        "TV[SEM=<\\\\X x.X(\\\\y.DRS([],[jump_into(x,y)]))>,tns=past] -> 'jumped' 'into'\n",
        "TV[SEM=<\\\\X x.X(\\\\y.DRS([],[follow(x,y)]))>,tns=past] -> 'followed'\n",
        "IV[SEM=<\\\\x.DRS([],[run_away(x)])>,tns=past] -> 'ran' 'away'\n",
        "TV[SEM=<\\\\X x.X(\\\\y.DRS([],[get_our_of(x,y)]))>,tns=past] -> 'got' 'out' 'of'\n",
        "\"\"\"\n",
        "\n",
        "with open('my_grammar.fcfg', 'w') as f:\n",
        "     f.write(grammar_str)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QrY75k3RU3Gn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0c358e2d-7868-4d95-a680-cc87710ee7cd"
      },
      "source": [
        "our_expression = []\n",
        "parser = load_parser('my_grammar.fcfg', logic_parser = nltk.sem.drt.DrtParser())\n",
        "\n",
        "drs_list = []\n",
        "for sent in target_sentences:\n",
        "    drs_list.append(parse_p(parser, sent))\n",
        "    print(\"The Target Sentence Is: ```\", tsent, \"```\")\n",
        "    print(drs_list[-1], '\\n')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The Target Sentence Is: ``` A white kitten got out of the jar ```\n",
            "([x,z430],[black(x), kitten(x), mouse(z430), see(x,z430)]) \n",
            "\n",
            "The Target Sentence Is: ``` A white kitten got out of the jar ```\n",
            "([x,z434],[PRO(x), kitten(x), PRO(z434), mouse(z434), rush_after(x,z434)]) \n",
            "\n",
            "The Target Sentence Is: ``` A white kitten got out of the jar ```\n",
            "([x,z438],[PRO(x), mouse(x), jar(z438), jump_into(x,z438)]) \n",
            "\n",
            "The Target Sentence Is: ``` A white kitten got out of the jar ```\n",
            "([x,z442],[PRO(x), kitten(x), PRO(z442), mouse(z442), follow(x,z442)]) \n",
            "\n",
            "The Target Sentence Is: ``` A white kitten got out of the jar ```\n",
            "([x],[PRO(x), mouse(x), run_away(x)]) \n",
            "\n",
            "The Target Sentence Is: ``` A white kitten got out of the jar ```\n",
            "([x,z448],[white(x), kitten(x), PRO(z448), jar(z448), get_our_of(x,z448)]) \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "id": "0b5unnEuVLpc",
        "outputId": "3e14fd4f-6c7a-43b0-f4e9-755809b4186a"
      },
      "source": [
        "sumup_drs = drs_list[0]\n",
        "for drs in drs_list[1:]:\n",
        "    sumup_drs += drs\n",
        "res = sumup_drs.simplify()\n",
        "res_str = res.__str__()\n",
        "res_str"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'([x,z430,z434,z438,z442,z448,z449,z450,z451,z452,z453],[black(x), kitten(x), mouse(z430), see(x,z430), PRO(z449), kitten(z449), PRO(z434), mouse(z434), rush_after(z449,z434), PRO(z450), mouse(z450), jar(z438), jump_into(z450,z438), PRO(z451), kitten(z451), PRO(z442), mouse(z442), follow(z451,z442), PRO(z452), mouse(z452), run_away(z452), white(z453), kitten(z453), PRO(z448), jar(z448), get_our_of(z453,z448)])'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 101
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KnoctC6lXtch"
      },
      "source": [
        "PRO Predicate"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "id": "RHw3Kwd5VRsb",
        "outputId": "3a8fd101-f1a4-4273-f6d7-9246d5da3890"
      },
      "source": [
        "resolution = [('z20', 'x'),  \n",
        "              ('z12', 'z10'),\n",
        "              ('z21', 'z10'),\n",
        "              ('z22', 'x'),\n",
        "              ('z16', 'z10'),\n",
        "              ('z23', 'z10'),\n",
        "              ('z19', 'z14')]\n",
        "for r in resolution:\n",
        "    pro = 'PRO(' + r[0] + ')'\n",
        "    antecedent = r[1] + '=' + r[0]\n",
        "    res_str = res_str.replace(pro, antecedent)\n",
        "res_str"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'([x,z430,z434,z438,z442,z448,z449,z450,z451,z452,z453],[black(x), kitten(x), mouse(z430), see(x,z430), PRO(z449), kitten(z449), PRO(z434), mouse(z434), rush_after(z449,z434), PRO(z450), mouse(z450), jar(z438), jump_into(z450,z438), PRO(z451), kitten(z451), PRO(z442), mouse(z442), follow(z451,z442), PRO(z452), mouse(z452), run_away(z452), white(z453), kitten(z453), PRO(z448), jar(z448), get_our_of(z453,z448)])'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 102
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JCnO6XTKXw5D",
        "outputId": "4d97ce5b-f5f1-4576-8dd0-2445980f6c63"
      },
      "source": [
        "new_res = nltk.DrtExpression.fromstring(res_str)\n",
        "new_res = new_res.eliminate_equality()\n",
        "new_res"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<DRS ([x,z430,z434,z438,z442,z448,z449,z450,z451,z452,z453],[black(x), kitten(x), mouse(z430), see(x,z430), PRO(z449), kitten(z449), PRO(z434), mouse(z434), rush_after(z449,z434), PRO(z450), mouse(z450), jar(z438), jump_into(z450,z438), PRO(z451), kitten(z451), PRO(z442), mouse(z442), follow(z451,z442), PRO(z452), mouse(z452), run_away(z452), white(z453), kitten(z453), PRO(z448), jar(z448), get_our_of(z453,z448)])>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 106
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "enOHYbFtd_gY",
        "outputId": "c371690f-1276-43a3-83f3-008d769d1a47"
      },
      "source": [
        "fol = new_res.fol()\n",
        "fol"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<ExistsExpression exists x z430 z434 z438 z442 z448 z449 z450 z451 z452 z453.(black(x) & kitten(x) & mouse(z430) & see(x,z430) & PRO(z449) & kitten(z449) & PRO(z434) & mouse(z434) & rush_after(z449,z434) & PRO(z450) & mouse(z450) & jar(z438) & jump_into(z450,z438) & PRO(z451) & kitten(z451) & PRO(z442) & mouse(z442) & follow(z451,z442) & PRO(z452) & mouse(z452) & run_away(z452) & white(z453) & kitten(z453) & PRO(z448) & jar(z448) & get_our_of(z453,z448))>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 115
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gnnOFuj1dkoy",
        "outputId": "0c388487-d259-4084-e7f9-1b4906dbb106"
      },
      "source": [
        "print(len(drs_list))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "6\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2Aw13a5Kdu77",
        "outputId": "b62002b4-99b0-4f19-fb8a-b421a3806223"
      },
      "source": [
        "print(type(drs_list[0]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'nltk.sem.drt.DRS'>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VEQ1KL2Xd0gS",
        "outputId": "88b1604d-5080-4e3c-9baf-d314302d6deb"
      },
      "source": [
        "list_drs = drs_list[0]\n",
        "for el in drs_list[1:]:\n",
        "  list_drs += el\n",
        "\n",
        "print(list_drs)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(([x,z430],[black(x), kitten(x), mouse(z430), see(x,z430)]) + ([x,z434],[PRO(x), kitten(x), PRO(z434), mouse(z434), rush_after(x,z434)]) + ([x,z438],[PRO(x), mouse(x), jar(z438), jump_into(x,z438)]) + ([x,z442],[PRO(x), kitten(x), PRO(z442), mouse(z442), follow(x,z442)]) + ([x],[PRO(x), mouse(x), run_away(x)]) + ([x,z448],[white(x), kitten(x), PRO(z448), jar(z448), get_our_of(x,z448)]))\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z-cxYwTsXyru",
        "outputId": "0bd3bdec-9f4d-4a44-b159-9b33988fdc34"
      },
      "source": [
        "list_drs.simplify()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<DRS ([x,z430,z434,z438,z442,z448,z454,z455,z456,z457,z458],[black(x), kitten(x), mouse(z430), see(x,z430), PRO(z454), kitten(z454), PRO(z434), mouse(z434), rush_after(z454,z434), PRO(z455), mouse(z455), jar(z438), jump_into(z455,z438), PRO(z456), kitten(z456), PRO(z442), mouse(z442), follow(z456,z442), PRO(z457), mouse(z457), run_away(z457), white(z458), kitten(z458), PRO(z448), jar(z448), get_our_of(z458,z448)])>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 116
        }
      ]
    }
  ]
}